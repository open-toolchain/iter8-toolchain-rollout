---
defaultBaseImageVersion: latest
properties:
- name: DEPLOYMENT_FILE
  value: ${DEPLOYMENT_FILE}
  type: text
- name: IBM_CLOUD_API_KEY
  value: ${API_KEY}
  type: secure
stages:
- name: BUILD
  inputs:
  - type: git
    branch: ${GIT_BRANCH}
    service: ${GIT_REPO}
  triggers:
  - type: commit
  properties:
  - name: DOCKER_ROOT
    value: ${DOCKER_ROOT}
    type: text
  - name: DOCKER_FILE
    value: Dockerfile
    type: text  
  jobs:
  - name: Pre-build check
    type: builder
    build_type: cr
    artifact_dir: ''
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${CF_APP_NAME}
    script: |-
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_prebuild.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_prebuild.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_prebuild.sh")

      # Lints Dockerfile and checks presence of registry namespace.
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_prebuild.sh")
  - name: Build Docker image
    type: builder
    build_type: cr
    artifact_dir: output
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${CF_APP_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/build_image.sh) and 'source' it from your pipeline job
      #    source ./scripts/build_image.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/build_image.sh")

      # This script does build a Docker image into IBM Container Service private image registry.
      # Minting image tag using format: BUILD_NUMBER-BRANCH-COMMIT_ID-TIMESTAMP
      # Also copies information into a build.properties file, so they can be reused later on by other scripts (e.g. image url, chart name, ...)
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/build_image_buildkit.sh")
- name: VALIDATE
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  jobs:
  - name: Vulnerability Advisor
    type: tester
    test_type: vulnerabilityadvisor
    use_image_from_build_input: true
    fail_stage: false
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_vulnerabilities.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_vulnerabilities.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_vulnerabilities.sh")

      # Check for vulnerabilities of built image using Vulnerability Advisor
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_vulnerabilities.sh")
- name: CHECK PREREQS
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: ROLLOUT_DASHBOARD
    value: ${ROLLOUT_DASHBOARD}
    type: text
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  - name: HOST
    value:
    type: text
  jobs:
  - name: Check Istio config
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # copy the script below into your app code repo (e.g. ./scripts/istio_check_install.sh) and 'source' it from your pipeline job
      #    source ./scripts/istio_check_install.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/istio_check_install.sh")

      # Check Istio installation in target cluster
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/istio_check_install.sh")
  - name: Check iter8 config
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/iter8_check_install.sh) and 'source' it from your pipeline job
      #    source ./scripts/iter8_check_install.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/iter8_check_install.sh")

      # Check Istio installation in target cluster
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/iter8_check_install.sh")
  - name: Check dashboard config
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # Import iter8's Grafana dashboard
      # https://github.com/iter8-tools/docs/blob/v0.2.1/doc_files/iter8_install.md#import-iter8s-grafana-dashboard

      kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath='{.items[0].metadata.name}') 3000:3000&

      source <(curl -sSL "https://raw.githubusercontent.com/iter8-tools/iter8-controller/v0.2.1/hack/grafana_install_dashboard.sh")
  - name: Check app config
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/bookinfo_check_install.sh) and 'source' it from your pipeline job
      #    source ./scripts/bookinfo_check_install.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/bookinfo_check_install.sh")

      # Check Istio installation in target cluster
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/bookinfo_check_install.sh")
- name: PREPARE CANDIDATE ROLLOUT
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: EXPERIMENT_TEMPLATE_FILE
    value: iter8/experiment.yaml
    type: text
  - name: EXPERIMENT_NAME
    value: 
    type: text
  jobs:
  - name: Prepare for Rollout
    type: builder
    curatedDockerImage: latest
    artifact_dir: ''
    build_type: shell
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # Identify experiment name to use
      if [ -z "${EXPERIMENT_TEMPLATE_FILE}" ]; then EXPERIMENT_TEMPLATE_FILE=iter8_experiment.yaml ; fi
      if [ ! -f ${EXPERIMENT_TEMPLATE_FILE} ]; then
        echo -e "${red}iter8 experiment template '${EXPERIMENT_TEMPLATE_FILE}' not found${no_color}"
      fi

      export EXPERIMENT_NAME=$(yq read ${EXPERIMENT_TEMPLATE_FILE} metadata.name)-${GIT_BRANCH}-${BUILD_NUMBER}
      echo "EXPERIMENT_NAME=${EXPERIMENT_NAME}"

      # Record names in build.properties for use by later stages
      #   append to existing build.properties if already defined
      cp build.properties $ARCHIVE_DIR/ || :
      echo "EXPERIMENT_NAME=${EXPERIMENT_NAME}" >> $ARCHIVE_DIR/build.properties
- name: ROLLOUT CANDIDATE
  inputs:
  - type: job
    stage: PREPARE CANDIDATE ROLLOUT
    job: Prepare for Rollout
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  - name: ROLLOUT_DASHBOARD
    value: ${ROLLOUT_DASHBOARD}
    type: text
  - name: PATCH_FILE
    value: kustomize/patch.yaml
    type: text
  - name: EXPERIMENT_TEMPLATE_FILE
    value: iter8/experiment.yaml
    type: text
  jobs:
  - name: Configure Rollout
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # Identify canary deployment name from the deployment yaml
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/create_deployment.sh")
      CANDIDATE_DEPLOYMENT_NAME=$(yq r ${DEPLOYMENT_FILE} metadata.name)

      # Identify baseline deployment by searching the cluster
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/identify_stable.sh")
      if [[ -z $BASELINE_DEPLOYMENT_NAME ]]; then BASELINE_DEPLOYMENT_NAME=$CANDIDATE_DEPLOYMENT_NAME; fi

      # Run canary experiment using iter8
      echo "BASELINE_DEPLOYMENT_NAME=${BASELINE_DEPLOYMENT_NAME}"
      echo "CANDIDATE_DEPLOYMENT_NAME=$CANDIDATE_DEPLOYMENT_NAME"
      ON_SUCCESS=candidate
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/create_experiment.sh")
  - name: Pre-deploy check
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_predeploy.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_predeploy_kubectl.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_predeploy_kubectl.sh")

      # Checks the cluster is ready, has a namespace configured with access to the private
      # image registry (using an IBM Cloud API Key). It also configures Helm Tiller service to later perform a deploy with Helm.
      touch ${DEPLOYMENT_FILE}
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_predeploy_kubectl.sh")
  - name: Deploy to Kubernetes
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/create_deployment.sh) and 'source' it from your pipeline job
      #    source ./scripts/create_deployment.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/create_deployment.sh")
      # Create canary deployment yaml
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/create_deployment.sh")

      # copy the script below into your app code repo (e.g. ./scripts/deploy_kubectl.sh) and 'source' it from your pipeline job
      #    source ./scripts/deploy_kubectl.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/deploy_kubectl.sh")
      # Create canary deployment yaml
      USE_ISTIO_GATEWAY=true
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/deploy_kubectl.sh")
      echo "Rollout Dashboard:"
      kubectl --namespace ${CLUSTER_NAMESPACE} get experiments.iter8.tools ${EXPERIMENT_NAME} --output jsonpath='{.status.grafanaURL}' || true
      echo ""
  - name: Wait and Cleanup
    type: deployer
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/wait_complete.sh) and 'source' it from your pipeline job
      #    source ./scripts/wait_complete.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/wait_complete.sh")

      # Check liveness and readiness probes to confirm application is healthy
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/wait_complete.sh")
- name: IMMEDIATE ROLLBACK
  inputs:
  - type: job
    stage: PREPARE CANDIDATE ROLLOUT
    job: Prepare for Rollout
  triggers:
  - type: stage
    enabled: false
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  jobs:
  - name: Rollback
    type: deployer
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # Override experiment as failure
      echo "Stop iter8 experiment if still running"
      kubectl --namespace ${CLUSTER_NAMESPACE} \
        patch experiment ${EXPERIMENT_NAME} \
        --type=json -p '[{"op": "add", "path": "/action", "value": "override_failure"}]' \
      || true # don't fail when the experiment can't be found

      # Wait for termination and delete canary deployment
      FORCE_TERMINATION=true
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/wait_complete.sh")
- name: IMMEDIATE ROLLFORWARD
  inputs:
  - type: job
    stage: PREPARE CANDIDATE ROLLOUT
    job: Prepare for Rollout
  triggers:
  - type: stage
    enabled: false
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  jobs:
  - name: Rollforward
    type: deployer
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # Override experiment as successful
      kubectl --namespace ${CLUSTER_NAMESPACE} \
        patch experiment ${EXPERIMENT_NAME} \
        --type=json -p '[{"op": "add", "path": "/action", "value": "override_success"}]' \
      || true # don't fail when the experiment can't be found

      # Wait for termination and delete baseline deployment
      FORCE_TERMINATION=true
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/iter8-toolchain-rollout/master/scripts/wait_complete.sh")
